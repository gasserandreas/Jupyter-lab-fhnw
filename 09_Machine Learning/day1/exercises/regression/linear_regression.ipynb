{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning - Aufgabenblatt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datensatz\n",
    "\n",
    "Wir arbeiten in dieser Aufgabenblatt mit dem `fish.csv` Datensatz.\n",
    "\n",
    "Es handelt sich um **157 Fische** die am Finland’s Lake Laengelmaevesi gefangen wurden und folgende **7 Features** wurden erhoben:\n",
    "\n",
    "| Feature | Descriptiopn                                                                  |\n",
    "|---------|-------------------------------------------------------------------------------|\n",
    "| Species | Fischspezies                                                                   |\n",
    "| Weight  | Gewicht vom Fisch (in Gramm)                                                  |\n",
    "| Length1 | Länge des Fisches von der Nase bis zum Schwanzansatz (in Zentimetern)         |\n",
    "| Length2 | Länge des Fisches von der Nase bis zur Schwanzkerbe (in Zentimetern)          |\n",
    "| Length3 | Länge des Fisches von der Nase bis zum Schwanzende (in Zentimetern)           |\n",
    "| Height  | Maximale Höhe des Fisches (in Zentimetern)                                    |\n",
    "| Width   | Maximale Breite des Fisches (in Zentimetern)                                  |\n",
    "\n",
    "### Weitere Links (Extra)\n",
    "\n",
    "* Kaggle Competition auf dem Datensatz: https://www.kaggle.com/aungpyaeap/fish-market \n",
    "* Beschreibung: https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/imlsug/imlsug_ugappdatasets_sect009.htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ziel\n",
    "\n",
    "Wir wollen in diesem Aufgabenblatt ein `lineares Modell` trainieren, dass als `Output` das Gewicht eines Fisches (`Weight`) anhand verschiedener `Features` vorhersagen kann.\n",
    "\n",
    "![Ziel dieses Aufgabenblattes](./img/goal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Das Einlesen der Daten wurde hier bereits gemacht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/fish.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aufgabe 1 - Train, Validation, Test Split\n",
    "\n",
    "In Aufgabe 1 teilen wir die Daten in\n",
    "* `Features` und `Zielvariable` (Aufgabe 1.1)\n",
    "* ein `Test-Set` und `Data-Set` (Aufgabe 1.2)\n",
    "* und anschliessend das `Data-Set` in ein `Train-Set` und `Validation-Set` (Aufgabe 1.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.1 - Aufteilen in Features und Zielvariable\n",
    "\n",
    "Zuerst müssen wir unser Datensatz in `Features` und `Zielvariable` aufteilen.\n",
    "Wir möchten das Gewicht eines Fisches vorhersagen können, also ist `Weight` unsere Zielvariable.\n",
    "Und wir behalten vorerst alle restlichen Features.\n",
    "\n",
    "1. Spalten Sie den Datensatz `df` in die Features `X` (alle Features/Spalten ausser `Weight`, mittels `df.drop`) und die Zielvariable `y` (hier `Weight`, mittels Basic-Indexing) auf.\n",
    "2. Achten Sie darauf, dass `X` ein `DataFrame` ist und `y` eine `Series` ist. Den Typ einer Variable X können sie in Python mittels `type(X)` herausfinden.\n",
    "3. Wieviele Zeilen und wieviele Spalten hat `X`? Nutzen Sie `X.shape`, um die Frage zu beantworten. Was für eine `shape` hat `y`?\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* Basic Indexing `df['col_name']`: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#basics\n",
    "* `drop`: Unter https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html Beispiel \"Drop columns\".\n",
    "* `shape`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html\n",
    "* `type`: https://www.programiz.com/python-programming/methods/built-in/type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.2 - Test-Set, Data-Set - `train_test_split`\n",
    "\n",
    "Im Theorie Teil haben wir das Aufteilen der Daten in `Train-Set`, `Validation-Set` und `Test-Set` angeschaut.\n",
    "\n",
    "![Train-Val-Test Split](./img/train-val-test.png)\n",
    "\n",
    "1. Teilen Sie unsere Daten (Features `X` und Zielvariable `y`) in ein `Test-Set` und `Data-Set` auf mittels `sklearn.model_selection.train_test_split`\n",
    "\n",
    "Das `Data-Set` teilen wir in Aufgabe 1.5 weiter auf.\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* `train_test_split`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 1.3 - Datenanalyse - Schauen wir uns die Daten mal an\n",
    "\n",
    "Wir können das Feature `Height` als X-Achse und die Zielvariabl `Weight` als Y-Achse in einem Scatter-Plot visualisieren:\n",
    "\n",
    "1. Erstellen Sie einen Scatter-Plot mit `Height` als X-Achse und `Weight` als Y-Achse mittels `sns.scatterplot`. `seaborn`s `scatterplot` erwartet ein DataFrame für den `data` Parameter. Um die geteilten Daten (`X_data`, `y_data`), wieder in ein DataFrame zu verwandeln, kann man `pd.concat` verwenden: `pd.concat([X_data, y_data], axis=1)`\n",
    "2. Was können Sie bereits anhand vom Scatter-Plot über die Performanz des linearen Modells sagen?\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* `sns.scatterplot`: https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "* Was ist ein Scatter-Plot: https://chartio.com/learn/charts/what-is-a-scatter-plot/\n",
    "* `pd.concat`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "* Pandas Cheat Sheet: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf, bei \"Reshaping Data\" ist `pd.concat` mit `axis=1` visuell dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# TODO"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.4 - Pairplot - `sns.pairplot`\n",
    "\n",
    "Den oben erstellten Scatter-Plot kann man auch systematisch auf alle Features und Zielvariable kombinationen anwenden. Seaborn bietet bereits eine Funktion dafür an.\n",
    "\n",
    "1. Erstellen Sie den pairplot mittels `sns.pairplot`.\n",
    "2. Interpretieren Sie den pairplot.\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* `sns.pairplot`: https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "* Video explaining pairplot: https://www.youtube.com/watch?v=uCgvlfIo9fg (zeigt auch weitere Optionen, die wir hier nicht anschauen)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# TODO"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 1.5 - Train-Set, Validation-Set - `train_test_split`\n",
    "\n",
    "In Aufgabe 1.2 haben wir die Daten (`df`) in `Data-Set` und `Test-Set` aufgeteilt. Anschliessend haben wir Datenanalyse auf dem `Data-Set` betrieben.\n",
    "\n",
    "In dieser Aufgabe teilen wir das `Data-Set` weiter in `Train-Set` und `Validation-Set` auf.\n",
    "\n",
    "![Train-Val-Test Split](./img/train-val-test.png)\n",
    "\n",
    "1. Teilen Sie das `Data-Set` (`X_data`, `y_data`) in ein `Train-Set` und `Validation-Set` auf mittels `sklearn.model_selection.train_test_split` (Analog zur Aufgabe 1.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Schlusswort Aufgabe 1\n",
    "\n",
    "In Aufgabe 1 haben wir das ursprüngliche DataFrame `df` in Features `X` und Zielvariable `y` unterteilt, und diese dann weiter in `Train-Set` (`X_train` und `y_train`), `Validation-Set` (`X_val` und `y_val`) sowie `Test-Set` (`X_test` und `y_test`) aufgeteilt.\n",
    "\n",
    "Wir haben bereit ein wenig Datenanalyse (Aufgabe 1.3 und Aufgabe 1.4) gemacht. \n",
    "Beachten Sie, dass wir mit Absicht nicht die `Test-Set` Daten plotteten.\n",
    "Wir wollen am Schluss ein unbiased estimate über die Performanz von unserem finalen Modell berechnen können.\n",
    "Als Selbstübung kann man noch weitere seaborn plots ausprobieren: https://seaborn.pydata.org/examples/index.html.\n",
    "Beispielsweise können Sie das Gewicht der Fische als Boxplot nach Fischspezies darstellen: https://seaborn.pydata.org/examples/grouped_boxplot.html\n",
    "\n",
    "Das `Train-Set` und `Validation-Set` verwenden wir in Aufgabe 2 und Aufgabe 3, um Modell zu trainieren und ein finales Modell zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Performanzmass\n",
    "\n",
    "Als Performanzmass für die Evaluierung des Modells nutzen wir den `RMSE` (`R`oot `M`ean `S`quared `E`rror):\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "RMSE(\\vec{y}, \\vec{\\hat{y}}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y^{(i)} - \\hat{y}^{(i)})^2}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Wobei $\\vec{y}$ die echten Fisch-Gewichte sind, und $\\vec{\\hat{y}}$ unsere Modellvorhersagen sind, und $N$ die Anzahl Datenpunkte ist.\n",
    "\n",
    "In diesem Aufgabenblatt ist das Performanzmass mit `RMSE` vorgegeben. **In eigenen Projekten muss man zum Beginn des Projektes ein sinnvolles Performanzmass festlegen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Einfaches Modell\n",
    "\n",
    "In Aufgabe 2 machen wir ein einfaches Lineares Modell mit **nur einem Feature**, dem Feature `Height`.\n",
    "\n",
    "Warum nur ein Feature? Weil es den Code einfacher macht und somit einfacher zu verstehen ist - also rein didaktische Gründe.\n",
    "Warum das Feature `Height`?\n",
    "Der Pairplot hat gezeigt, dass es einen Zusammenhang zwischen `Height` und `Weight` gibt, wir hätten aber auch `Width` nehmen können.\n",
    "\n",
    "Wir wollen also ein Modell trainieren, dass anhand der Höhe des Fisches (`Height`), das Gewicht (`Weight`) des Fisches vorhersagt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 2.1 - Feature selektieren\n",
    "\n",
    "1. Selektieren Sie von `X_train` nur das Feature `Height` mittels Basic-Indexing und verwandeln Sie, wenn nötig die Series in ein DataFrame mittels `s.to_frame()`. Benennen Sie die Variable mit dem neue DataFrame `X_train_height`.\n",
    "2. Untersuchen Sie den type des erstellten DataFrames mittels `type(df)`. Es sollte ein DataFrame sein.\n",
    "3. Untersuchen Sie die Dimensionen des erstellten DataFrames mittels `df.shape`. Es sollte die Dimensionen (89, 1) haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 2.2 - Erstes Lineares Modell - `LinearRegression`, `lr.fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun wollen wir ein erstes Lineares Modell mit einem Feature auf dem `Train-Set` (`X_train_height`, `y_train`) trainieren (`fit`)\n",
    "und anschliessend die Performanz unseres Modelles auf unseren `Validation-Set` (`X_val_height`, `y_val`) evaluieren.\n",
    "\n",
    "1. Erstellen Sie ein Lineares Regressions Modell mittels `LinearRegression` und trainineren Sie es auf dem `Train-Set` (`X_train_height`, `y_train`) mittels `lr.fit`.\n",
    "2. Verwenden Sie das in 1. trainierte Modell und sagen Sie die Zielvariable auf dem `Validation-Set` (`X_val_height`, `y_train`) voraus mittels `lr.predict`. `X_val_height` müssen Sie noch analog zur Aufgabe 2.1 erstellen. Die Vorhersagen nennen wir `y_val_hat`.\n",
    "3. Warum braucht `predict` nur die Validierungs-Features (`X_val`) und nicht die Validierungs-Zielvariable (`y_val`) wie z.B. `fit`?\n",
    "4. Messen Sie den `RMSE`, den wir auf dem `Validation-Set` machen mittels `sklearn.metrics.mean_squared_error(..., squred=False)`, unseren Vorhersagen `y_val_hat` und den tatsächlichen Fisch-Gewichten `y_val`.\n",
    "5. (Extra) Messen Sie analog zu 4. den `RMSE` auf dem `Train-Set`. Wie Unterscheidet sich diese Betrachtung von 4.? Warum macht es Sinn, diese Werte zu vergleichen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (Extra) Aufgabe 2.3 - Visuallisierung unseres Modells\n",
    "\n",
    "In Aufgabe 2.2 haben wir unser erstes Modell trainiert.\n",
    "Wir können dieses nun in den scatter plot von Aufgabe 1.3 plotten.\n",
    "\n",
    "Aus dem Theoretischen Teil wissen wir, dass das Lineare Modell folgende Form hat:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y^{(i)} = \\beta_0 + \\beta_{1}x^{(i)}_1 + \\beta_{2}x^{(i)}_2 + \\cdots + \\beta_{p}x^{(i)}_p + \\varepsilon^{(i)}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Wenn wir nur von **einem Feature** (wie in Aufgabe 2.2) ausgehen, vereinfacht sich das zu:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y^{(i)} = \\beta_0 + \\beta_{1}x^{(i)}_1\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Wenn wir $\\beta_0$ umbennen zu $n$ und $\\beta_{1}$ umbennen zu $m$, entspricht dies der Geradengleichung (https://de.wikipedia.org/wiki/Geradengleichung):\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y = n + m * x\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "**Das Modell ist also einfach eine Gerade** im 2-dimensionalen Raum. Sprich wir können das Modell als Linie in den 2-dimensionalen scatter plot von Aufgabe 1.2 zeichnen.\n",
    "\n",
    "1. Lese den gelernten Y-Achsen-Abschnitt (intercept) aus der Linearen Regression aus mittels `lr.intercept_`. `lr.intercept_` entspricht $\\beta_0$.\n",
    "2. Lese die gelernte Steigung (Slope) aus der Linearen Regression aus mittels `lr.coef_[0]`. `lr.coef_[0]` entspricht $\\beta_1$.\n",
    "3. Zeichnen Sie eine Linie in den scatter plot von Aufgabe 1.2 mittels beispielsweise `plt.plot`.\n",
    "4. Analysieren Sie den Plot. Ist unser Modell gut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Schlusswort Aufgabe 2\n",
    "\n",
    "Glückwunsch Sie haben Ihr erstes Machine Learning Modell trainiert. Gehen Sie die Schritte noch einmal in Ruhe durch, wenn Ihnen nicht ganz klar ist, warum wir einzelne Schritte gemacht haben.\n",
    "\n",
    "In Aufgabe 3 werden wir das Modell verbessern, indem wir **weitere Features** hinzufügen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3 - Feature Engineering und Feature Selection\n",
    "\n",
    "In Aufgabe 2 haben wir schrittweise ein erstes Modell erstellt, um das Gewicht (`Weight`) eines Fisches vorherzusagen.\n",
    "Nun geht es darum weitere Features zu betrachten, dabei stellen sich folgende Fragen:\n",
    "\n",
    "* Welche Features brauchen ein Preprocessing - genannt `Feature Preprocessing` (Aufgabe 3.1)\n",
    "* Welche Features können wir zusätzlich \"erstellen\" - genannt `Feature Engineering` (Aufgabe 3.2)\n",
    "* Welche Features sollen wir überhaupt in Betracht ziehen? - genannt `Feature Selection` (Aufgabe 3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 3.1 - Feature Preprocessing - `OneHotEncoder`\n",
    "\n",
    "Wenn wir ein **nicht numerische** Features, wie beispielsweise der Name der Fischspezies (`Species`) haben, können wir das Feature nicht einfach in ein Lineares Regressions Modell geben, da das Modell eine Zahl erwartet.\n",
    "\n",
    "Bei der Linearen Regression ist das Resultat schliesslich eine gewichtete Summe der Inputs, wie will man einen Text gewichten und dann aufsummieren?\n",
    "Wenn $x^{(i)}_1$ beispielsweise `\"Roach\"` wäre, ist nicht klar was das Modell machen müsste:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y^{(i)} = \\beta_0 + \\beta_{1}x^{(i)}_1 + \\beta_{2}x^{(i)}_2 + \\cdots + \\beta_{p}x^{(i)}_p + \\varepsilon^{(i)}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Für diesen Fall, haben wir im Theorieblock bereits vom `One-Hot-Encoding` gehört.\n",
    "Hier fügen wir einfach für jede Spezienart ein weitere Feature hinzu, wie beispielsweise ein Feature `Roach`. Hat ein Fisch die Spezies `Roach` ist der Wert `1`, ansonsten den Wert `0`.\n",
    "Hier ist der Ablauf dargestellt:\n",
    "\n",
    "![One-Hot-Encoding example](./img/one-hot-encoding.png)\n",
    "\n",
    "1. Nutzen Sie den `OneHotEncoder` von `sklearn.preprocessing`. Zuerst müssen Sie den `OneHotEncoder` auf den `Species` \"trainieren\" mittels `fit`. Anschliessend können wir die `Species` dann transformieren (das `One-Hot-Encoding` durchführen) mittels `transform`.\n",
    "2. Analysieren Sie den Typ `type` und die Shape `shape` vom Resultat von Schritt 1.\n",
    "3. Das Resultat von Schritt 1 müssen wir zuerst in ein `pd.DataFrame` packen mit gleichem index wie unsere Daten `X_train` und den entsprechenden Spaltennamen. Dies kann mittels `pd.DataFrame(..., index=X_train.index, columns=ohe.categories[0])` gemacht werden.\n",
    "4. Das DataFrame von Schritt 2 können wir dann mit `pd.concat([X_train.drop(columns='Species'), X_train_species], axis=1)` zu unseren Daten anfügen. Nennen Sie das Resultat `X_train_ohe`.\n",
    "\n",
    "#### Hilfreiche Links\n",
    "* One-Hot-Encoder: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "* (Extra) Encoding categorical features: https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 3.2 - Alle Features\n",
    "\n",
    "Das Resultat von Aufgabe 3.1 ist ein DataFrame mit allen Featuren bereit für ein Modell.\n",
    "In dieser Aufgabe trainieren (`fit`) wir blindlings eine `LinearRegression` auf allen Features.\n",
    "\n",
    "1. Erstellen Sie ein Lineares Regressions Modell mittels `LinearRegression()` und trainineren Sie es auf dem `Train-Set` (`X_train_ohe`, `y_train`) mittels `lr.fit`.\n",
    "2. Verwenden Sie das in 1. trainierte Modell und predicten Sie die Zielvariable auf dem `Validation-Set` mittels `lr.predict`. Die Vorhersagen nennen wir `y_val_hat`.\n",
    "    - Hinweis: Wir müssen `X_val` analog zu `X_train` in  Aufgabe 3.1 noch zu `X_val_ohe` preprocessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 3.3 - Cross-Validation - `sklearn.model_selection.cross_val_predict`\n",
    "\n",
    "In Aufgabe 1 haben wir das `Data-Set` einmal in ein `Train-Set` und `Validation-Set` aufgeteil und in Aufgabe 2 ein Modell auf dem `Train-Set` trainiert (`fit`) und danach auf dem `Validation-Set` validiert (`predict`).\n",
    "\n",
    "Die somit gemessene Performanz auf dem `Validation-Set` ist stark abhängig von diesem einen `Validation-Set`.\n",
    "Und wiederholen wir die Schritte mit einer anderen zufälligen Aufteilung in `Train-Set` und `Validation-Set`, kann die gemessene Perfomanz schwanken.\n",
    "\n",
    "Wir können die tatsächliche Performanz unseres Modelles stabiler berechnen mit der im Theorie Teil vorgestellten `K-Fold-Cross-Validation`.\n",
    "\n",
    "Dazu teilen wir das `Data-Set` systematisch in `k` (also beispielsweise 5) verschiedene `Train-Set` und `Validation-Set` auf,\n",
    "wobei ein `Validation-Set` immer $\\frac{1}{5}$ aller Datenpunkte beinhaltet und jeder Datenpunkt **genau einmal** in einem diesen 5 `Validation-Set`s vorkommt.\n",
    "\n",
    "![K-Fold-Cross-Validation](./img/k-fold-cross-validation.png)\n",
    "\n",
    "Anschliessend wird immer ein neues Modell auf einem `Train-Set` trainiert und die Werte auf dem `Validation-Set` vorhergesagt und gespeichert.\n",
    "Nachdem wir das für alle 5 `Train-Set`s und `Validation-Set`s dies gemacht haben, haben wir für **jeden Datenpunkt im `Data-Set` eine Vorhersage** gemacht und gespeichert. \n",
    "Wir mussten dafür aber 5 Modelle trainieren.\n",
    "\n",
    "1. Man kann das oben beschriebene Verfahren mit `for` Schleifen selbst implementieren, aber `sklearn` bietet bereits eine vorgefertigte Lösung. Wenden Sie `sklearn.model_selection.cross_val_predict` auf die `LinearRegression` und dem `Data-Set` (`X_data`, `y_data`) an.\n",
    "    - `X_data` analog zu Aufgabe 3.1 preprocessen.\n",
    "2. Was genau ist der `cv` Parameter? Experimentieren Sie.\n",
    "3. (Extra) Es gibt weitere Funktionen wie `cross_val_score` (https://scikit-learn.org/stable/modules/classes.html#model-validation). Was machen diese?\n",
    "4. (Extra) Implementieren Sie die Cross-Validation mit `for` Schleifen selbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3.4 - Feature Engineering\n",
    "\n",
    "Es ist oft wichtig aus den bestehenden Features für das zugrundeliegende Problem sinnvolle Features zu \"basteln\" (`engineeren`). Oft fliesst bei diesem Schritt Expertenwissen der jeweiligen Domäne ein.\n",
    "Für das bestimmen vom Gewicht eines Fisches, ist beispielsweise das `Volumnen` nützlich.\n",
    "\n",
    "1. Approximieren Sie das Volumen eines Fisches auf dem `Data-Set` mit den Featuren `Height`, `Width` und `Length3` (alle multiplizieren).\n",
    "    - Nenne Sie das neue Feature `approx_Volume`\n",
    "2. Vergleichen Sie alle Features ohne `approx_Volume` (Aufgabe 3.3) und alle Features mit `approx_Volume` mittels `cross_val_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (Extra) Aufgabe 3.5 - Feature Selection\n",
    "\n",
    "Im Fall vom Fisch Datensatz funktioniert es erstaunlich gut, einfach blindlings alle Features zu nehmen.\n",
    "Dies liegt daran, dass wir für die Anzahl Features okay viele Datenpunkte haben. Wir haben 89 Datenpunkte im `Train-Set` für 6 Features (12 Features nach dem One-Hot-Encoding). Daher kommt es zu keinem `Overfitting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können trotzdem versuchen die Anzahl Features zu reduzieren. Dies kann auch trotz Performanzverlust vom Modell sinnvoll sein.\n",
    "Beispielsweise müsste ein hypothetischer Benutzer weniger Daten in einem Formular eingeben, wenn man das Modell über ein Benutzerinterface zugängig macht.\n",
    "\n",
    "In dieser Aufgabe versuchen wir die `4` wichtigsten Features mittels `sklearn.feature_selection.RFE` zu bestimmen.\n",
    "\n",
    "1. Versuechen Sie manuell `4` Features auszuwählen und evaluieren Sie ein Modell mittels `cross_val_predict`.\n",
    "2. Erstellen Sie ein `sklearn.feature_selection.RFE` mit einer `LinearRegression()` und `n_features_to_select=4` als Parameter. `fit`en Sie `RFE` mit dem `Data-Set` (`X_data_ohe_engineered`, `y_data`).\n",
    "    - Bemerkung: `RFE` erwartet skalierte Features, skalieren Sie daher die Features zuerst mittels `sklearn.preprocessing.StandardScaler`.\n",
    "3. Evaluieren Sie die Performanz gefundenen Features `rfe.get_support()` mittels `Cross Validation`.\n",
    "4. Das Ergebniss aus Schritt 3. ist ein biased estimate der echten Performanz, warum?\n",
    "5. Wiederholen Sie Schritt 3 mit `sklearn.feature_selection.SelectKBest`.\n",
    "6. Wiederholen Sie Schritt 3 mit `sklearn.feature_selection.SelectFromModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### (Extra) Weitere Schritte\n",
    "* Feature selection: https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Schlusswort Aufgabe 3\n",
    "\n",
    "Wir haben angefangen das Problem mit Linearen Modellen zu lösen. In der Praxis würde man noch deutlich mehr probieren, beispeislweise:\n",
    "\n",
    "* Systematisches `Feature Engineering` mit `PolynomialFeatures`: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "* Abgeschwächte `Feature Selection` mittels `Regularisierung` auf diesen erstellten Features, wie `Lasso` oder `Ridge`.\n",
    "* Intelligentes `Feature Engineering` indem man Wissen von Fachpersonen (hier z.B. Fischverkäufer) in neue Features einfliessen lässt.\n",
    "\n",
    "Für eine erste Übung haben wir aber schon viel getan. In der nächsten Übung bestimmen wir die Performanz unseres finalen Projektes mittels dem `Test-Set`.\n",
    "In der Praxis würden wir dies am Ende des Projektes tun, damit wir ein unbiased Estimate über die Performanz unseres Modells haben.\n",
    "Dieses Estimate ist vielleicht für die Kommunikation mit den Vorgesetzten, möglichen Kunden entscheidend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aufgabe 4 - Test Set\n",
    "\n",
    "In Aufgabe 1.2 haben wir das `Test-Set` (`X_test`, `y_test`) erstellt und beiseite gelegt. Nun wollen wir das gefundene Modell auf diesem `Test-Set` evaluieren.\n",
    "\n",
    "1. Nehmen Sie ein Modell aus einer vorherigen Aufgabe als finales Modell.\n",
    "2. Wenden Sie dieses Modell auf dem `Test-Set` (`X_test`, `y_test`) an. `X_test` muss allenfalls noch entsprechend verarbeitet werden (`One Hot Encoding`, etc.)\n",
    "3. Bestimmen Sie den `RMSE` auf den Vorhersagen von Schritt 2 und `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Schlusswort Aufgabenblatt 2\n",
    "\n",
    "Wir haben Konzepte kennen gelernt, die wir immer wieder antreffen werden, wie das Aufteilen in `Train-Set`, `Validation-Set` und `Test-Set`, wie auch das trainieren (`fit`) eines sklearn Modelles (`LinearRegression`).\n",
    "\n",
    "### (Extra) Pipeline\n",
    "\n",
    "Vielleicht ist Ihnen aufgefallen, dass wir oft die gleiche Schritte, wie `One-Hot-Encoding`, auf allen drei Datensätze (`Train-Set`, `Validation-Set`, `Test-Set`) anwenden mussten.\n",
    "Um das handlicher zu machen, gibt es im sklearn das Konzept der `Pipeline`.\n",
    "\n",
    "Für interessierte kann ich empfehlen sich darin einzulesen: https://scikit-learn.org/stable/modules/compose.html\n",
    "Man kann diese Aufgaben auch mit Pipelines lösen.\n",
    "\n",
    "sklearn Pipelines werden wir ansonsten im `Machine Learning Lab` wieder antreffen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}