{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning - Aufgabenblatt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datensatz\n",
    "\n",
    "Wir arbeiten in dieser Aufgabenblatt mit dem `fish.csv` Datensatz.\n",
    "\n",
    "Es handelt sich um **157 Fische** die am Finland’s Lake Laengelmaevesi gefangen wurden und folgende **7 Features** wurden erhoben:\n",
    "\n",
    "| Feature | Descriptiopn                                                                  |\n",
    "|---------|-------------------------------------------------------------------------------|\n",
    "| Species | Fischspezies                                                                   |\n",
    "| Weight  | Gewicht vom Fisch (in Gramm)                                                  |\n",
    "| Length1 | Länge des Fisches von der Nase bis zum Schwanzansatz (in Zentimetern)         |\n",
    "| Length2 | Länge des Fisches von der Nase bis zur Schwanzkerbe (in Zentimetern)          |\n",
    "| Length3 | Länge des Fisches von der Nase bis zum Schwanzende (in Zentimetern)           |\n",
    "| Height  | Maximale Höhe des Fisches (in Zentimetern)                                    |\n",
    "| Width   | Maximale Breite des Fisches (in Zentimetern)                                  |\n",
    "\n",
    "### Weitere Links (Extra)\n",
    "\n",
    "* Kaggle Competition auf dem Datensatz: https://www.kaggle.com/aungpyaeap/fish-market \n",
    "* Beschreibung: https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/imlsug/imlsug_ugappdatasets_sect009.htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ziel\n",
    "\n",
    "Wir wollen in diesem Aufgabenblatt ein `lineares Modell` trainieren, dass als `Output` das Gewicht eines Fisches (`Weight`) anhand verschiedener `Features` vorhersagen kann.\n",
    "\n",
    "![Ziel dieses Aufgabenblattes](./img/goal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Das Einlesen der Daten wurde hier bereits gemacht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/fish.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aufgabe 1 - Train, Validation, Test Split\n",
    "\n",
    "In Aufgabe 1 teilen wir die Daten in\n",
    "* `Features` und `Zielvariable` (Aufgabe 1.1)\n",
    "* ein `Test-Set` und `Data-Set` (Aufgabe 1.2)\n",
    "* und anschliessend das `Data-Set` in ein `Train-Set` und `Validation-Set` (Aufgabe 1.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.1 - Aufteilen in Features und Zielvariable\n",
    "\n",
    "Zuerst müssen wir unser Datensatz in `Features` und `Zielvariable` aufteilen.\n",
    "Wir möchten das Gewicht eines Fisches vorhersagen können, also ist `Weight` unsere Zielvariable.\n",
    "Und wir behalten vorerst alle restlichen Features.\n",
    "\n",
    "1. Spalten Sie den Datensatz `df` in die Features `X` (alle Features/Spalten ausser `Weight`, mittels `df.drop`) und die Zielvariable `y` (hier `Weight`, mittels Basic-Indexing) auf.\n",
    "2. Achten Sie darauf, dass `X` ein `DataFrame` ist und `y` eine `Series` ist. Den Typ einer Variable X können sie in Python mittels `type(X)` herausfinden.\n",
    "3. Wieviele Zeilen und wieviele Spalten hat `X`? Nutzen Sie `X.shape`, um die Frage zu beantworten. Was für eine `shape` hat `y`?\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* Basic Indexing `df['col_name']`: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#basics\n",
    "* `drop`: Unter https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html Beispiel \"Drop columns\".\n",
    "* `shape`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html\n",
    "* `type`: https://www.programiz.com/python-programming/methods/built-in/type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. `drop`\n",
    "X = df.drop(columns='Weight')\n",
    "y = df['Weight']\n",
    "\n",
    "# 2.\n",
    "# X ist ein pandas DataFrame (Matrix mit Features Namen)\n",
    "print(\"type(X):\", type(X))\n",
    "# y ist eine pandas.Series (Vektor mit Feature Name)\n",
    "print(\"type(y):\", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3.\n",
    "# X hat 159 Zeilen/Datenpunkte und 6 Spalten/Features.\n",
    "print(\"X.shape:\", X.shape)\n",
    "# y hat 159 Zeilen/Datenpunkte und \"keine\" Spalte.\n",
    "# Series haben keine Spalten, sondern sind angeordnete Werte (hier 159 Werte).\n",
    "# Die shape ist daher (159, ), dies entspricht einer Series in pandas (bzw. einem Vektor in numpy)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.2 - Test-Set, Data-Set - `train_test_split`\n",
    "\n",
    "Im Theorie Teil haben wir das Aufteilen der Daten in `Train-Set`, `Validation-Set` und `Test-Set` angeschaut.\n",
    "\n",
    "![Train-Val-Test Split](./img/train-val-test.png)\n",
    "\n",
    "1. Teilen Sie unsere Daten (Features `X` und Zielvariable `y`) in ein `Test-Set` und `Data-Set` auf mittels `sklearn.model_selection.train_test_split`\n",
    "\n",
    "Das `Data-Set` teilen wir in Aufgabe 1.5 weiter auf.\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* `train_test_split`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Vor dem Split...\")\n",
    "print(X.shape, type(X))\n",
    "print(y.shape, type(y))\n",
    "\n",
    "# Es ist oft sinnvoll die Daten vor dem Split noch zu mischeln (shuffle=True)\n",
    "# Falls die Daten (X, y) allenfalls eine vordefinierte Ordnung (z.B. chronologisch) haben.\n",
    "# random_state wird hier fixiert, dass der Musterlösung Output immer gleich ist.\n",
    "X_data, X_test, y_data, y_test = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"... ist nach dem Split:\")\n",
    "# Von unseren 159 Datenpunkten sind 119 Datenpunkte im Train-Set und 40 Datenpunkte im Validation-Set\n",
    "# Beachten Sie, dass sich der Typ nicht verändert hat. y war eine pandas.Series (Vektor mit Feature Name) und X war ein pandas DataFrame (1-spaltige Matrix mit Feature Name)\n",
    "print(X_data.shape, type(X_data), sep='\\t')\n",
    "print(y_data.shape, type(y_data), sep='\\t')\n",
    "\n",
    "print(X_test.shape, type(X_test), sep='\\t')\n",
    "print(y_test.shape, type(y_test), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wichtig: Das `Test-Set` werden wir **bis zur letzten Aufgabe nicht mehr anfassen**. Die Idee vom Test-Set ist **am Ende eines Machine Learning Projektes** ein unbiased estimate über die Performanz vom finalen Modell zu erhalten.\n",
    "Es darf also **nicht** in die Modellfindung (Model-Selection) einfliessen.\n",
    "\n",
    "In diesen Aufgabenblättern ist es (wahrscheinlich) Overkill extra ein Test-Set zu erstellen. \n",
    "Es ist aber wichtig, dass Sie den vollständigen Ablauf sehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 1.3 - Datenanalyse - Schauen wir uns die Daten mal an\n",
    "\n",
    "Wir können das Feature `Height` als X-Achse und die Zielvariabl `Weight` als Y-Achse in einem Scatter-Plot visualisieren:\n",
    "\n",
    "1. Erstellen Sie einen Scatter-Plot mit `Height` als X-Achse und `Weight` als Y-Achse mittels `sns.scatterplot`. `seaborn`s `scatterplot` erwartet ein DataFrame für den `data` Parameter. Um die geteilten Daten (`X_data`, `y_data`), wieder in ein DataFrame zu verwandeln, kann man `pd.concat` verwenden: `pd.concat([X_data, y_data], axis=1)`\n",
    "2. Was können Sie bereits anhand vom Scatter-Plot über die Performanz des linearen Modells sagen?\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* `sns.scatterplot`: https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "* Was ist ein Scatter-Plot: https://chartio.com/learn/charts/what-is-a-scatter-plot/\n",
    "* `pd.concat`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "* Pandas Cheat Sheet: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf, bei \"Reshaping Data\" ist `pd.concat` mit `axis=1` visuell dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Beachten Sie, dass wir bereits hier nur auf X_data gehen, nicht auf df und nicht auf X_test, y_test.\n",
    "# X_test sollte *nicht* in unseren Entscheidungsprozess einfliessen - also auch nicht bei der Datenanalyse verwenden.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1.\n",
    "sns.scatterplot(data=pd.concat([X_data, y_data], axis=1), x='Height', y='Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\.\n",
    "Im Scatter-Plot sieht man einen klaren **nicht-linearen** Zusammenhang zwischen dem Feature `Height` und der Zielvariable `Weight` - die Punkte liegen auf Kurven, nicht auf Geraden.\n",
    "Wir sehen auch mehrere unterschiedliche Fälle, die wir anhand von `Height` nicht unterscheiden können.\n",
    "Beispielsweise bei Height = 12.5, soll das Modell ~350 oder ~1000 vorhersagen (Siehe plot unten)? Weitere Features könnten helfen diese Fälle zu unterscheiden, beispielsweise um welche Spezies es sich handelt.\n",
    "Wir brauchen also sicherlich weitere Features als nur `Height`, um das Gewicht eines Fisches gut vorhersagen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = sns.scatterplot(data=pd.concat([X_data, y_data], axis=1), x='Height', y='Weight')\n",
    "a.plot([12.5],[350],'o',ms=60,mec='r',mfc='none')\n",
    "a.plot([12.5],[1000],'o',ms=60,mec='r',mfc='none')\n",
    "plt.axvline(12.5, 0, c='red')\n",
    "plt.title(\"Was vorhersagen für beispielsweise Height=12.5?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ein Lineares Modell auf nur diesem Feature (Aufgabe 2) wird also sicherlich Underfitten.\n",
    "In Aufgabe 3 erweitern wir das Lineare Modell aus Aufgabe 2 um weitere Features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1.4 - Pairplot - `sns.pairplot`\n",
    "\n",
    "Den oben erstellten Scatter-Plot kann man auch systematisch auf alle Features und Zielvariable kombinationen anwenden. Seaborn bietet bereits eine Funktion dafür an.\n",
    "\n",
    "1. Erstellen Sie den pairplot mittels `sns.pairplot`.\n",
    "2. Interpretieren Sie den pairplot.\n",
    "\n",
    "#### Hilfreiche Links\n",
    "\n",
    "* `sns.pairplot`: https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "* Video explaining pairplot: https://www.youtube.com/watch?v=uCgvlfIo9fg (zeigt auch weitere Optionen, die wir hier nicht anschauen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "sns.pairplot(pd.concat([X_data, y_data], axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Wir sehen, dass die `Length1`, `Lenght2` und `Length3` Features **stark korrelieren** (linear zusammenhängen) - liest man die Feature Beschreibung zu Beginn des Aufgabenblattes überrascht dies nicht. Wir sehen, das Gewicht (`Weight`) hat einen scheinbar polynomieller Zusammenhang mit den Längen (z.B. `Length1`), der Höhe (`Height`) und der Breite (`Width`) des Fisches. Dies nutzen wir in Aufgabe 3 aus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 1.5 - Train-Set, Validation-Set - `train_test_split`\n",
    "\n",
    "In Aufgabe 1.2 haben wir die Daten (`df`) in `Data-Set` und `Test-Set` aufgeteilt. Anschliessend haben wir Datenanalyse auf dem `Data-Set` betrieben.\n",
    "\n",
    "In dieser Aufgabe teilen wir das `Data-Set` weiter in `Train-Set` und `Validation-Set` auf.\n",
    "\n",
    "![Train-Val-Test Split](./img/train-val-test.png)\n",
    "\n",
    "1. Teilen Sie das `Data-Set` (`X_data`, `y_data`) in ein `Train-Set` und `Validation-Set` auf mittels `sklearn.model_selection.train_test_split` (Analog zur Aufgabe 1.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Vor dem Split...\")\n",
    "# Beachten Sie, dass wir hier X_data verwenden: Also alle Daten ausserhalb des Test-Sets.\n",
    "print(X_data.shape, type(X_data))\n",
    "print(y_data.shape, type(y_data))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, random_state=0, shuffle=True)\n",
    "\n",
    "print(\"... ist nach dem Split:\")\n",
    "# Von unseren 119 Datenpunkten sind 89 Datenpunkte im Train-Set und 30 Datenpunkte im Validation-Set\n",
    "# Beachten Sie, dass sich der Typ nicht verändert hat. y war eine pandas.Series (Vektor mit Feature Name) und X war ein pandas DataFrame (1-spaltige Matrix mit Feature Name)\n",
    "print(X_train.shape, type(X_train), sep='\\t')\n",
    "print(y_train.shape, type(y_train), sep='\\t')\n",
    "\n",
    "print(X_val.shape, type(X_val), sep='\\t')\n",
    "print(y_val.shape, type(y_val), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Schlusswort Aufgabe 1\n",
    "\n",
    "In Aufgabe 1 haben wir das ursprüngliche DataFrame `df` in Features `X` und Zielvariable `y` unterteilt, und diese dann weiter in `Train-Set` (`X_train` und `y_train`), `Validation-Set` (`X_val` und `y_val`) sowie `Test-Set` (`X_test` und `y_test`) aufgeteilt.\n",
    "\n",
    "Wir haben bereit ein wenig Datenanalyse (Aufgabe 1.3 und Aufgabe 1.4) gemacht. \n",
    "Beachten Sie, dass wir mit Absicht nicht die `Test-Set` Daten plotteten.\n",
    "Wir wollen am Schluss ein unbiased estimate über die Performanz von unserem finalen Modell berechnen können.\n",
    "Als Selbstübung kann man noch weitere seaborn plots ausprobieren: https://seaborn.pydata.org/examples/index.html.\n",
    "Beispielsweise können Sie das Gewicht der Fische als Boxplot nach Fischspezies darstellen: https://seaborn.pydata.org/examples/grouped_boxplot.html\n",
    "\n",
    "Das `Train-Set` und `Validation-Set` verwenden wir in Aufgabe 2 und Aufgabe 3, um Modell zu trainieren und ein finales Modell zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Performanzmass\n",
    "\n",
    "Als Performanzmass für die Evaluierung des Modells nutzen wir den `RMSE` (`R`oot `M`ean `S`quared `E`rror):\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "RMSE(\\vec{y}, \\vec{\\hat{y}}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y^{(i)} - \\hat{y}^{(i)})^2}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Wobei $\\vec{y}$ die echten Fisch-Gewichte sind, und $\\vec{\\hat{y}}$ unsere Modellvorhersagen sind, und $N$ die Anzahl Datenpunkte ist.\n",
    "\n",
    "In diesem Aufgabenblatt ist das Performanzmass mit `RMSE` vorgegeben. **In eigenen Projekten muss man zum Beginn des Projektes ein sinnvolles Performanzmass festlegen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Einfaches Modell\n",
    "\n",
    "In Aufgabe 2 machen wir ein einfaches Lineares Modell mit **nur einem Feature**, dem Feature `Height`.\n",
    "\n",
    "Warum nur ein Feature? Weil es den Code einfacher macht und somit einfacher zu verstehen ist - also rein didaktische Gründe.\n",
    "Warum das Feature `Height`?\n",
    "Der Pairplot hat gezeigt, dass es einen Zusammenhang zwischen `Height` und `Weight` gibt, wir hätten aber auch `Width` nehmen können.\n",
    "\n",
    "Wir wollen also ein Modell trainieren, dass anhand der Höhe des Fisches (`Height`), das Gewicht (`Weight`) des Fisches vorhersagt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 2.1 - Feature selektieren\n",
    "\n",
    "1. Selektieren Sie von `X_train` nur das Feature `Height` mittels Basic-Indexing und verwandeln Sie, wenn nötig die Series in ein DataFrame mittels `s.to_frame()`. Benennen Sie die Variable mit dem neue DataFrame `X_train_height`.\n",
    "2. Untersuchen Sie den type des erstellten DataFrames mittels `type(df)`. Es sollte ein DataFrame sein.\n",
    "3. Untersuchen Sie die Dimensionen des erstellten DataFrames mittels `df.shape`. Es sollte die Dimensionen (89, 1) haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Mit Basic Indexing und s.to_frame()\n",
    "X_train_height = X_train['Height'].to_frame()\n",
    "\n",
    "# 1. Alternative: Select Features mit Basic Indexing direkt als 1-spaltiges DataFrame.\n",
    "del X_train_height\n",
    "X_train_height = X_train[['Height']]  # Ist equivalent zu X = df['Height'].to_frame()\n",
    "\n",
    "# 2. X_train_height soll ein pd.DataFrame sein\n",
    "print(type(X_train_height))\n",
    "\n",
    "# 3. Shape sollte (89, 1) sein.\n",
    "print(X_train_height.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 2.2 - Erstes Lineares Modell - `LinearRegression`, `lr.fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun wollen wir ein erstes Lineares Modell mit einem Feature auf dem `Train-Set` (`X_train_height`, `y_train`) trainieren (`fit`)\n",
    "und anschliessend die Performanz unseres Modelles auf unseren `Validation-Set` (`X_val_height`, `y_val`) evaluieren.\n",
    "\n",
    "1. Erstellen Sie ein Lineares Regressions Modell mittels `LinearRegression` und trainineren Sie es auf dem `Train-Set` (`X_train_height`, `y_train`) mittels `lr.fit`.\n",
    "2. Verwenden Sie das in 1. trainierte Modell und sagen Sie die Zielvariable auf dem `Validation-Set` (`X_val_height`, `y_train`) voraus mittels `lr.predict`. `X_val_height` müssen Sie noch analog zur Aufgabe 2.1 erstellen. Die Vorhersagen nennen wir `y_val_hat`.\n",
    "3. Warum braucht `predict` nur die Validierungs-Features (`X_val`) und nicht die Validierungs-Zielvariable (`y_val`) wie z.B. `fit`?\n",
    "4. Messen Sie den `RMSE`, den wir auf dem `Validation-Set` machen mittels `sklearn.metrics.mean_squared_error(..., squred=False)`, unseren Vorhersagen `y_val_hat` und den tatsächlichen Fisch-Gewichten `y_val`.\n",
    "5. (Extra) Messen Sie analog zu 4. den `RMSE` auf dem `Train-Set`. Wie Unterscheidet sich diese Betrachtung von 4.? Warum macht es Sinn, diese Werte zu vergleichen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1.\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_height, y_train)\n",
    "\n",
    "# 2.\n",
    "X_val_height = X_val[['Height']]\n",
    "y_val_hat = lr.predict(X_val_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3\\.\n",
    "Bei `fit` trainieren wir das Modell. Wir wollen also, dass es die Input-Output Beziehung anhand von den übergebenen Daten lernt, dazu benötigt das Modell die dazugehörenden Outputs (`y_train`).\n",
    "Bei `predict` fragen wir den vorgeschlagenen Output vom Modell für neue Datenpunkte ab.\n",
    "Das Modell lernt beiim Vorhersagen (`predict`) nichts, das Modell braucht also keine dazugehörenden Outputs.\n",
    "Die Validation-Zielvariablen `y_val` verwenden wir im Schritt 4. für die Bestimmung vom Fehler, welcher das Modell macht.\n",
    "Ohne die echten Outputs `y_val` könnten wir den Fehler vom Modell nicht bestimmen, da wir nur die Vorhersage hätten, nicht aber die echten Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4.\n",
    "print(mean_squared_error(y_val, y_val_hat, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5.\n",
    "y_train_hat = lr.predict(X_train[['Height']])\n",
    "print(mean_squared_error(y_train, y_train_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5\\.\n",
    "Die Performanz auf den `Train-Set` ist wichtig, da wir es mit der Performanz auf dem `Validation-Set` vergleichen können, um `Overfitting` und `Underfitting` feststellen zu können:\n",
    "- Ähnliche Werte (wie wir es in der Musterlösung haben) kann allenfalls `Underfitting` sein.\n",
    "- Bessere Werte auf dem `Training-Set` deutet `Overfitting` an.\n",
    "- Bessere Werte auf dem `Validation-Set` deutet auf ein zufällig einfacheres `Validation-Set` hin, `Cross-Validation` kann helfen (Siehe Aufgabe 3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (Extra) Aufgabe 2.3 - Visuallisierung unseres Modells\n",
    "\n",
    "In Aufgabe 2.2 haben wir unser erstes Modell trainiert.\n",
    "Wir können dieses nun in den scatter plot von Aufgabe 1.3 plotten.\n",
    "\n",
    "Aus dem Theoretischen Teil wissen wir, dass das Lineare Modell folgende Form hat:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y^{(i)} = \\beta_0 + \\beta_{1}x^{(i)}_1 + \\beta_{2}x^{(i)}_2 + \\cdots + \\beta_{p}x^{(i)}_p + \\varepsilon^{(i)}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Wenn wir nur von **einem Feature** (wie in Aufgabe 2.2) ausgehen, vereinfacht sich das zu:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y^{(i)} = \\beta_0 + \\beta_{1}x^{(i)}_1\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Wenn wir $\\beta_0$ umbennen zu $n$ und $\\beta_{1}$ umbennen zu $m$, entspricht dies der Geradengleichung (https://de.wikipedia.org/wiki/Geradengleichung):\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y = n + m * x\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "**Das Modell ist also einfach eine Gerade** im 2-dimensionalen Raum. Sprich wir können das Modell als Linie in den 2-dimensionalen scatter plot von Aufgabe 1.2 zeichnen.\n",
    "\n",
    "1. Lese den gelernten Y-Achsen-Abschnitt (intercept) aus der Linearen Regression aus mittels `lr.intercept_`. `lr.intercept_` entspricht $\\beta_0$.\n",
    "2. Lese die gelernte Steigung (Slope) aus der Linearen Regression aus mittels `lr.coef_[0]`. `lr.coef_[0]` entspricht $\\beta_1$.\n",
    "3. Zeichnen Sie eine Linie in den scatter plot von Aufgabe 1.2 mittels beispielsweise `plt.plot`.\n",
    "4. Analysieren Sie den Plot. Ist unser Modell gut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "b = lr.intercept_\n",
    "# 2.\n",
    "m = lr.coef_[0]\n",
    "\n",
    "print(\"learned Intercept\", b)\n",
    "print(\"learned Slope\", m)\n",
    "\n",
    "# 3.\n",
    "\n",
    "# Auslesen der minimalen Höhe und maximalen Höhe aller Fische\n",
    "x_min = X_data[['Height']].min()\n",
    "x_max = X_data[['Height']].max()\n",
    "\n",
    "# Berechnen der jeweilige Vorhersage unseres Modells (hier manuell)\n",
    "y_min_hat = b + m * x_min\n",
    "y_max_hat = b + m * x_max\n",
    "\n",
    "# Alternative: Berechnen der jeweilige Vorhersage unseres Modells (hier mit dem gefitteten Modell)\n",
    "del y_min_hat; del y_max_hat\n",
    "y_min_hat = lr.predict([x_min])\n",
    "y_max_hat = lr.predict([x_max])\n",
    "\n",
    "# Kopieren den scatter plot von Aufgabe 1.2\n",
    "plt.title(\"scatter plot von Aufgabe 1.2 mit unserem ersten Modell\")\n",
    "sns.scatterplot(data=pd.concat([X_data[['Height']], y_data], axis=1), x='Height', y='Weight')\n",
    "# Zeichnen einer Linie der Vorhersagen mittels plt.plot\n",
    "plt.plot([x_min, x_max], [y_min_hat, y_max_hat], marker='o', linewidth=1, c='red')\n",
    "\n",
    "plt.legend(['model', 'data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4\\.\n",
    "Die zugrundeliegenden Daten sind klar nicht linear, wir verwenden aber ein lineraes Modell.\n",
    "Das Modell `underfittet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Schlusswort Aufgabe 2\n",
    "\n",
    "Glückwunsch Sie haben Ihr erstes Machine Learning Modell trainiert. Gehen Sie die Schritte noch einmal in Ruhe durch, wenn Ihnen nicht ganz klar ist, warum wir einzelne Schritte gemacht haben.\n",
    "\n",
    "In Aufgabe 3 werden wir das Modell verbessern, indem wir **weitere Features** hinzufügen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3 - Feature Engineering und Feature Selection\n",
    "\n",
    "In Aufgabe 2 haben wir schrittweise ein erstes Modell erstellt, um das Gewicht (`Weight`) eines Fisches vorherzusagen.\n",
    "Nun geht es darum weitere Features zu betrachten, dabei stellen sich folgende Fragen:\n",
    "\n",
    "* Welche Features brauchen ein Preprocessing - genannt `Feature Preprocessing` (Aufgabe 3.1)\n",
    "* Welche Features können wir zusätzlich \"erstellen\" - genannt `Feature Engineering` (Aufgabe 3.2)\n",
    "* Welche Features sollen wir überhaupt in Betracht ziehen? - genannt `Feature Selection` (Aufgabe 3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 3.1 - Feature Preprocessing - `OneHotEncoder`\n",
    "\n",
    "Wenn wir ein **nicht numerische** Features, wie beispielsweise der Name der Fischspezies (`Species`) haben, können wir das Feature nicht einfach in ein Lineares Regressions Modell geben, da das Modell eine Zahl erwartet.\n",
    "\n",
    "Bei der Linearen Regression ist das Resultat schliesslich eine gewichtete Summe der Inputs, wie will man einen Text gewichten und dann aufsummieren?\n",
    "Wenn $x^{(i)}_1$ beispielsweise `\"Roach\"` wäre, ist nicht klar was das Modell machen müsste:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "y^{(i)} = \\beta_0 + \\beta_{1}x^{(i)}_1 + \\beta_{2}x^{(i)}_2 + \\cdots + \\beta_{p}x^{(i)}_p + \\varepsilon^{(i)}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Für diesen Fall, haben wir im Theorieblock bereits vom `One-Hot-Encoding` gehört.\n",
    "Hier fügen wir einfach für jede Spezienart ein weitere Feature hinzu, wie beispielsweise ein Feature `Roach`. Hat ein Fisch die Spezies `Roach` ist der Wert `1`, ansonsten den Wert `0`.\n",
    "Hier ist der Ablauf dargestellt:\n",
    "\n",
    "![One-Hot-Encoding example](./img/one-hot-encoding.png)\n",
    "\n",
    "1. Nutzen Sie den `OneHotEncoder` von `sklearn.preprocessing`. Zuerst müssen Sie den `OneHotEncoder` auf den `Species` \"trainieren\" mittels `fit`. Anschliessend können wir die `Species` dann transformieren (das `One-Hot-Encoding` durchführen) mittels `transform`.\n",
    "2. Analysieren Sie den Typ `type` und die Shape `shape` vom Resultat von Schritt 1.\n",
    "3. Das Resultat von Schritt 1 müssen wir zuerst in ein `pd.DataFrame` packen mit gleichem index wie unsere Daten `X_train` und den entsprechenden Spaltennamen. Dies kann mittels `pd.DataFrame(..., index=X_train.index, columns=ohe.categories[0])` gemacht werden.\n",
    "4. Das DataFrame von Schritt 2 können wir dann mit `pd.concat([X_train.drop(columns='Species'), X_train_species], axis=1)` zu unseren Daten anfügen. Nennen Sie das Resultat `X_train_ohe`.\n",
    "\n",
    "#### Hilfreiche Links\n",
    "* One-Hot-Encoder: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "* (Extra) Encoding categorical features: https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# In .fit merkt sich der ohe welche Spezien es gibt.\n",
    "ohe.fit(X_train[['Species']])\n",
    "# In .transform wird das One-Hot-Encoding gemacht.\n",
    "X_train_ohe_species = ohe.transform(X_train[['Species']])\n",
    "\n",
    "# Alternative: Wir könnten fit und transform auch beide zusammen mittels fit_transform durchführen.\n",
    "del X_train_ohe_species\n",
    "X_train_ohe_species = ohe.fit_transform(X_train[['Species']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.\n",
    "print(type(X_train_ohe_species))\n",
    "print(X_train_ohe_species.shape)\n",
    "\n",
    "# 3. Verwandle die Matrix zu einem DataFrame\n",
    "X_train_species = pd.DataFrame(data=X_train_ohe_species.toarray(), index=X_train.index, columns=ohe.categories_[0])\n",
    "\n",
    "# 4. Verbinde One Hot Encoded Features mit den anderen Features.\n",
    "X_train_ohe = pd.concat([X_train.drop(columns='Species'), X_train_species], axis=1)\n",
    "\n",
    "# Wir haben die Spalte / Feature 'Species' nicht mehr, dafür für jedemögliche Spezies eine Spalte / Feature\n",
    "display(X_train_ohe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 3.2 - Alle Features\n",
    "\n",
    "Das Resultat von Aufgabe 3.1 ist ein DataFrame mit allen Featuren bereit für ein Modell.\n",
    "In dieser Aufgabe trainieren (`fit`) wir blindlings eine `LinearRegression` auf allen Features.\n",
    "\n",
    "1. Erstellen Sie ein Lineares Regressions Modell mittels `LinearRegression()` und trainineren Sie es auf dem `Train-Set` (`X_train_ohe`, `y_train`) mittels `lr.fit`.\n",
    "2. Verwenden Sie das in 1. trainierte Modell und predicten Sie die Zielvariable auf dem `Validation-Set` mittels `lr.predict`. Die Vorhersagen nennen wir `y_val_hat`.\n",
    "    - Hinweis: Wir müssen `X_val` analog zu `X_train` in  Aufgabe 3.1 noch zu `X_val_ohe` preprocessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_ohe, y_train)\n",
    "\n",
    "# 2.\n",
    "X_val_ohe_species = ohe.transform(X_val[['Species']])\n",
    "X_val_species = pd.DataFrame(data=X_val_ohe_species.toarray(), index=X_val.index, columns=ohe.categories_[0])\n",
    "X_val_ohe = pd.concat([X_val.drop(columns='Species'), X_val_species], axis=1)\n",
    "\n",
    "display(X_val_ohe.head())\n",
    "\n",
    "y_val_hat = lr.predict(X_val_ohe)\n",
    "\n",
    "print(mean_squared_error(y_val, y_val_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen eine deutliche Verbesserung vom `RMSE` auf dem `Validation Set` hier (alle Features) zu Aufgabe 2 (ein Feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe 3.3 - Cross-Validation - `sklearn.model_selection.cross_val_predict`\n",
    "\n",
    "In Aufgabe 1 haben wir das `Data-Set` einmal in ein `Train-Set` und `Validation-Set` aufgeteil und in Aufgabe 2 ein Modell auf dem `Train-Set` trainiert (`fit`) und danach auf dem `Validation-Set` validiert (`predict`).\n",
    "\n",
    "Die somit gemessene Performanz auf dem `Validation-Set` ist stark abhängig von diesem einen `Validation-Set`.\n",
    "Und wiederholen wir die Schritte mit einer anderen zufälligen Aufteilung in `Train-Set` und `Validation-Set`, kann die gemessene Perfomanz schwanken.\n",
    "\n",
    "Wir können die tatsächliche Performanz unseres Modelles stabiler berechnen mit der im Theorie Teil vorgestellten `K-Fold-Cross-Validation`.\n",
    "\n",
    "Dazu teilen wir das `Data-Set` systematisch in `k` (also beispielsweise 5) verschiedene `Train-Set` und `Validation-Set` auf,\n",
    "wobei ein `Validation-Set` immer $\\frac{1}{5}$ aller Datenpunkte beinhaltet und jeder Datenpunkt **genau einmal** in einem diesen 5 `Validation-Set`s vorkommt.\n",
    "\n",
    "![K-Fold-Cross-Validation](./img/k-fold-cross-validation.png)\n",
    "\n",
    "Anschliessend wird immer ein neues Modell auf einem `Train-Set` trainiert und die Werte auf dem `Validation-Set` vorhergesagt und gespeichert.\n",
    "Nachdem wir das für alle 5 `Train-Set`s und `Validation-Set`s dies gemacht haben, haben wir für **jeden Datenpunkt im `Data-Set` eine Vorhersage** gemacht und gespeichert. \n",
    "Wir mussten dafür aber 5 Modelle trainieren.\n",
    "\n",
    "1. Man kann das oben beschriebene Verfahren mit `for` Schleifen selbst implementieren, aber `sklearn` bietet bereits eine vorgefertigte Lösung. Wenden Sie `sklearn.model_selection.cross_val_predict` auf die `LinearRegression` und dem `Data-Set` (`X_data`, `y_data`) an.\n",
    "    - `X_data` analog zu Aufgabe 3.1 preprocessen.\n",
    "2. Was genau ist der `cv` Parameter? Experimentieren Sie.\n",
    "3. (Extra) Es gibt weitere Funktionen wie `cross_val_score` (https://scikit-learn.org/stable/modules/classes.html#model-validation). Was machen diese?\n",
    "4. (Extra) Implementieren Sie die Cross-Validation mit `for` Schleifen selbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# 1.\n",
    "\n",
    "# X_data analog zu Aufgabe 3.1 preprocessen.\n",
    "X_data_ohe_species = OneHotEncoder().fit_transform(X_data[['Species']])\n",
    "X_data_species = pd.DataFrame(data=X_data_ohe_species.toarray(), index=X_data.index, columns=ohe.categories_[0])\n",
    "X_data_ohe = pd.concat([X_data.drop(columns='Species'), X_data_species], axis=1)\n",
    "\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe, y_data, cv=5)\n",
    "print(mean_squared_error(y_data, y_data_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2\\.\n",
    "Der `cv` Parameter entspricht dem `k` in der Aufgabenbeschreibung.\n",
    "Je höher der Wert, desto stabiler die Vorhersage, aber je grösser auch der Rechenaufwand (da wir `k` Modelle trainieren müssen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3\\. und 4\\. nicht Teil der Musterlösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3.4 - Feature Engineering\n",
    "\n",
    "Es ist oft wichtig aus den bestehenden Features für das zugrundeliegende Problem sinnvolle Features zu \"basteln\" (`engineeren`). Oft fliesst bei diesem Schritt Expertenwissen der jeweiligen Domäne ein.\n",
    "Für das bestimmen vom Gewicht eines Fisches, ist beispielsweise das `Volumnen` nützlich.\n",
    "\n",
    "1. Approximieren Sie das Volumen eines Fisches auf dem `Data-Set` mit den Featuren `Height`, `Width` und `Length3` (alle multiplizieren).\n",
    "    - Nenne Sie das neue Feature `approx_Volume`\n",
    "2. Vergleichen Sie alle Features ohne `approx_Volume` (Aufgabe 3.3) und alle Features mit `approx_Volume` mittels `cross_val_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "X_data_ohe_engineered = X_data_ohe.copy()\n",
    "X_data_ohe_engineered['approx_Volume'] = X_data_ohe_engineered['Height'] * X_data_ohe_engineered['Width'] * X_data_ohe_engineered['Length3']\n",
    "\n",
    "# 2.\n",
    "\n",
    "# Cross Validation mit allen Features ohne approx_Volume (von Aufgabe 3.3)\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe, y_data, cv=5)\n",
    "print(mean_squared_error(y_data, y_data_hat, squared=False))\n",
    "\n",
    "# Cross Validation mit allen Features mit approx_Volume\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe_engineered, y_data, cv=5)\n",
    "print(mean_squared_error(y_data, y_data_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (Extra) Aufgabe 3.5 - Feature Selection\n",
    "\n",
    "Im Fall vom Fisch Datensatz funktioniert es erstaunlich gut, einfach blindlings alle Features zu nehmen.\n",
    "Dies liegt daran, dass wir für die Anzahl Features okay viele Datenpunkte haben. Wir haben 89 Datenpunkte im `Train-Set` für 6 Features (12 Features nach dem One-Hot-Encoding). Daher kommt es zu keinem `Overfitting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können trotzdem versuchen die Anzahl Features zu reduzieren. Dies kann auch trotz Performanzverlust vom Modell sinnvoll sein.\n",
    "Beispielsweise müsste ein hypothetischer Benutzer weniger Daten in einem Formular eingeben, wenn man das Modell über ein Benutzerinterface zugängig macht.\n",
    "\n",
    "In dieser Aufgabe versuchen wir die `4` wichtigsten Features mittels `sklearn.feature_selection.RFE` zu bestimmen.\n",
    "\n",
    "1. Versuechen Sie manuell `4` Features auszuwählen und evaluieren Sie ein Modell mittels `cross_val_predict`.\n",
    "2. Erstellen Sie ein `sklearn.feature_selection.RFE` mit einer `LinearRegression()` und `n_features_to_select=4` als Parameter. `fit`en Sie `RFE` mit dem `Data-Set` (`X_data_ohe_engineered`, `y_data`).\n",
    "    - Bemerkung: `RFE` erwartet skalierte Features, skalieren Sie daher die Features zuerst mittels `sklearn.preprocessing.StandardScaler`.\n",
    "3. Evaluieren Sie die Performanz gefundenen Features `rfe.get_support()` mittels `Cross Validation`.\n",
    "4. Das Ergebniss aus Schritt 3. ist ein biased estimate der echten Performanz, warum?\n",
    "5. Wiederholen Sie Schritt 3 mit `sklearn.feature_selection.SelectKBest`.\n",
    "6. Wiederholen Sie Schritt 3 mit `sklearn.feature_selection.SelectFromModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation mit allen Features\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe_engineered, y_data, cv=5)\n",
    "print(\"All Features:\", mean_squared_error(y_data, y_data_hat, squared=False))\n",
    "\n",
    "# 1. Manuelle Feature Selection\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe_engineered[['approx_Volume', 'Width', 'Height', 'Length1']], y_data, cv=5)\n",
    "print(f\"Manuell 4 Feature Selection:\", mean_squared_error(y_data, y_data_hat, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2.\n",
    "rfe = RFE(LinearRegression(), n_features_to_select=k)\n",
    "# Bemerkung: RFE erwartet skalierte Features (andernfalls stimmen die Feature Wichtigkeiten nicht).\n",
    "rfe.fit(StandardScaler().fit_transform(X_data_ohe_engineered), y_data)\n",
    "\n",
    "# 3.\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe_engineered[X_data_ohe_engineered.columns[rfe.get_support()]], y_data, cv=5)\n",
    "print(\"RFE\")\n",
    "print(\"Selektierte Features: \", list(X_data_ohe_engineered.columns[rfe.get_support()]))\n",
    "print(f\"Automatic {k} Feature Selection:\", mean_squared_error(y_data, y_data_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\.\n",
    "Wir selektieren die Features anhand des `Data-Set`. Anschliessend führen wir `Cross Validation` auf den Features aus. Die Datenpunkte, die wir für die `Feature Selection` verwendeten, sind die gleichen, die wir in der `Cross Validation` verwenden. Der Messwert der `Cross Validation` ist hier also nicht unbiased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5.\n",
    "k_best = SelectKBest(mutual_info_regression, k=k)\n",
    "k_best.fit(StandardScaler().fit_transform(X_data_ohe_engineered), y_data)\n",
    "\n",
    "# Cross Validation mit k besten Features.\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe_engineered[X_data_ohe_engineered.columns[k_best.get_support()]], y_data, cv=5)\n",
    "print(\"SelectKBest\")\n",
    "print(\"Selektierte Features: \", list(X_data_ohe_engineered.columns[k_best.get_support()]))\n",
    "print(f\"Automatic {k} Feature Selection:\", mean_squared_error(y_data, y_data_hat, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.\n",
    "from_model = SelectFromModel(LinearRegression(), max_features=k)\n",
    "from_model.fit(StandardScaler().fit_transform(X_data_ohe_engineered), y_data)\n",
    "\n",
    "# Cross Validation mit k besten Features.\n",
    "y_data_hat = cross_val_predict(LinearRegression(), X_data_ohe_engineered[X_data_ohe_engineered.columns[from_model.get_support()]], y_data, cv=5)\n",
    "print(\"SelectFromModel\")\n",
    "print(\"Selektierte Features: \", list(X_data_ohe_engineered.columns[from_model.get_support()]))\n",
    "print(f\"Automatic {k} Feature Selection:\", mean_squared_error(y_data, y_data_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### (Extra) Weitere Schritte\n",
    "* Feature selection: https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Schlusswort Aufgabe 3\n",
    "\n",
    "Wir haben angefangen das Problem mit Linearen Modellen zu lösen. In der Praxis würde man noch deutlich mehr probieren, beispeislweise:\n",
    "\n",
    "* Systematisches `Feature Engineering` mit `PolynomialFeatures`: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "* Abgeschwächte `Feature Selection` mittels `Regularisierung` auf diesen erstellten Features, wie `Lasso` oder `Ridge`.\n",
    "* Intelligentes `Feature Engineering` indem man Wissen von Fachpersonen (hier z.B. Fischverkäufer) in neue Features einfliessen lässt.\n",
    "\n",
    "Für eine erste Übung haben wir aber schon viel getan. In der nächsten Übung bestimmen wir die Performanz unseres finalen Projektes mittels dem `Test-Set`.\n",
    "In der Praxis würden wir dies am Ende des Projektes tun, damit wir ein unbiased Estimate über die Performanz unseres Modells haben.\n",
    "Dieses Estimate ist vielleicht für die Kommunikation mit den Vorgesetzten, möglichen Kunden entscheidend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aufgabe 4 - Test Set\n",
    "\n",
    "In Aufgabe 1.2 haben wir das `Test-Set` (`X_test`, `y_test`) erstellt und beiseite gelegt. Nun wollen wir das gefundene Modell auf diesem `Test-Set` evaluieren.\n",
    "\n",
    "1. Nehmen Sie ein Modell aus einer vorherigen Aufgabe als finales Modell.\n",
    "2. Wenden Sie dieses Modell auf dem `Test-Set` (`X_test`, `y_test`) an. `X_test` muss allenfalls noch entsprechend verarbeitet werden (`One Hot Encoding`, etc.)\n",
    "3. Bestimmen Sie den `RMSE` auf den Vorhersagen von Schritt 2 und `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. \n",
    "# Wir fitten das Modell aus Aufgabe 3.4 auf dem gesamten Data-Set (Train-Set und Validation-Set), so nutzen wir mehr Daten. Für das finale Modell kann dies gemacht werden.\n",
    "final_model = LinearRegression().fit(X_data_ohe_engineered, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.\n",
    "X_test_ohe_species = ohe.transform(X_test[['Species']])\n",
    "X_test_species = pd.DataFrame(data=X_test_ohe_species.toarray(), index=X_test.index, columns=ohe.categories_[0])\n",
    "X_test_ohe = pd.concat([X_test.drop(columns='Species'), X_test_species], axis=1)\n",
    "\n",
    "X_test_ohe_engineered = X_test_ohe.copy()\n",
    "\n",
    "X_test_ohe_engineered['approx_Volume'] = X_test_ohe_engineered['Height'] * X_test_ohe_engineered['Width'] * X_test_ohe_engineered['Length3']\n",
    "\n",
    "# 3.\n",
    "y_test_hat = final_model.predict(X_test_ohe_engineered)\n",
    "\n",
    "print(mean_squared_error(y_test, y_test_hat, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Schlusswort Aufgabenblatt 2\n",
    "\n",
    "Wir haben Konzepte kennen gelernt, die wir immer wieder antreffen werden, wie das Aufteilen in `Train-Set`, `Validation-Set` und `Test-Set`, wie auch das trainieren (`fit`) eines sklearn Modelles (`LinearRegression`).\n",
    "\n",
    "### (Extra) Pipeline\n",
    "\n",
    "Vielleicht ist Ihnen aufgefallen, dass wir oft die gleiche Schritte, wie `One-Hot-Encoding`, auf allen drei Datensätze (`Train-Set`, `Validation-Set`, `Test-Set`) anwenden mussten.\n",
    "Um das handlicher zu machen, gibt es im sklearn das Konzept der `Pipeline`.\n",
    "\n",
    "Für interessierte kann ich empfehlen sich darin einzulesen: https://scikit-learn.org/stable/modules/compose.html\n",
    "Man kann diese Aufgaben auch mit Pipelines lösen.\n",
    "\n",
    "sklearn Pipelines werden wir ansonsten im `Machine Learning Lab` wieder antreffen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}