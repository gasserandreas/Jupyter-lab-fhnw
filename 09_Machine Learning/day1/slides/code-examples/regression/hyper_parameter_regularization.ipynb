{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hyper Parameter - Beispiel Regularization\n",
    "\n",
    "Code-Beispiel für das Konzept von Hyper-Parametern am Beispiel der Regularisierungsstärke (`alpha`) im `Ridge` Modell.\n",
    "Zudem wird die Hyper-Parameter Suche mittels `GridSearchCV` und `RandomizedSearchCV` am Beispiel gezeigt.\n",
    "\n",
    "Die Hyper-Parameter Suche ist ein generelles Konzept. Wir werden noch komplexere Modelle mit mehreren Hyper-Parametern im Kurs kennenlernen. `GridSearchCV` und `RandomizedSearchCV` können analog verwendet werden."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fish.csv')[['Width', 'Weight']].rename(columns={\n",
    "    'Width': 'width (cm)',\n",
    "    'Weight': 'weight (g)'\n",
    "})\n",
    "X=df[['width (cm)']]\n",
    "y=df['weight (g)']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mehrere Parameter selbst ausprobieren\n",
    "\n",
    "Hier machen wir die `GridSearch` selbst. In Praxis verwendet man lieber `GridSearchCV`, anstatt es selbst zu programmieren.\n",
    "Der Code hier soll einzig helfen besser zu verstehen, was `GridSearchCV` genau macht.\n",
    "\n",
    "Wir nutzen hier `sklearn.linear_model.Ridge`. `Ridge` ist die `Linear Regression mit L2-Regularisierung`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1 => 34989.628195318706\n",
      "alpha=1.0 => 34863.77036591203\n",
      "alpha=10.0 => 34303.160119822445\n"
     ]
    }
   ],
   "source": [
    "model_01 = Pipeline([\n",
    "    ('std', StandardScaler()),      # Für Regularisierung Daten vorher standard skalieren.\n",
    "    ('ridge', Ridge(alpha=0.1))     # alpha heisst lambda in Folien.\n",
    "])\n",
    "y_hat = cross_val_predict(model_01, X, y)\n",
    "print(f\"alpha=0.1 => {mean_squared_error(y, y_hat)}\")\n",
    "\n",
    "model_1 = Pipeline([\n",
    "    ('std', StandardScaler()),      # Für Regularisierung Daten vorher standard skalieren.\n",
    "    ('ridge', Ridge(alpha=1.0))     # alpha heisst lambda in Folien.\n",
    "])\n",
    "y_hat = cross_val_predict(model_1, X, y)\n",
    "print(f\"alpha=1.0 => {mean_squared_error(y, y_hat)}\")\n",
    "\n",
    "model_10 = Pipeline([\n",
    "    ('std', StandardScaler()),      # Für Regularisierung Daten vorher standard skalieren.\n",
    "    ('ridge', Ridge(alpha=10.0))    # alpha heisst lambda in Folien.\n",
    "])\n",
    "y_hat = cross_val_predict(model_10, X, y)\n",
    "print(f\"alpha=10.0 => {mean_squared_error(y, y_hat)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier ist scheinbar eine starke Regularisierung (`alpha=10.0`) besser. Es wäre hier sinnvoll noch grössere alphas auszuprobieren."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mehrere Parameter mit `GridSearchCV` ausprobieren\n",
    "\n",
    "`GridSearchCV` probiert alle gegebenen Parameter Kombinationen durch. Für jede Kombination führt es eine K-Fold-Cross-Validation durch und misst welche Kombination am besten funktioniert. Die beste Kombination von Parametern wird in `best_params_` gespeichert. Die Anzahl an Kombinationen wird bei vielen Hyperparametern schnell gross, meistens ist dann `RandomizedSearchCV` besser geeignet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs.best_params_={'ridge__alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "    Pipeline([\n",
    "        ('std', StandardScaler()),  # Für Regularisierung Daten vorher standard skalieren.\n",
    "        ('ridge', Ridge())          # alpha wird später von GridSearchCV gesetzt (param_grid)\n",
    "    ]),\n",
    "    param_grid={\n",
    "        'ridge__alpha': [0.1, 1.0, 10]  # Probiere folgende Werte aus\n",
    "    },\n",
    "    scoring='neg_mean_squared_error'    # Wähle bestes Modell mit höchstem negativen MSE (bzw. tiefstem MSE).\n",
    ")\n",
    "\n",
    "gs.fit(X, y)\n",
    "\n",
    "print(f\"{gs.best_params_=}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mehrere Parameter mit `RandomizedSearchCV` ausprobieren\n",
    "\n",
    "`RandomizedSearchCV` probiert `n_iter` (hier 10) zufällige Parameter Kombinationen durch. Für jede Kombination führt es eine K-Fold-Cross-Validation durch und misst welche Kombination am besten funktioniert. Die beste Kombination von Parametern wird in `best_params_` gespeichert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs.best_params_={'ridge__alpha': 9.64026132896019}\n"
     ]
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(\n",
    "    Pipeline([\n",
    "        ('std', StandardScaler()),  # Für Regularisierung Daten vorher standard skalieren.\n",
    "        ('ridge', Ridge())          # alpha wird später von GridSearchCV gesetzt (param_grid)\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'ridge__alpha': uniform(0.1, 10-0.1)    # Wähle zufälliges alpha gleich-verteilt (uniform) zwischen 0.1 und 10.0\n",
    "    },\n",
    "    n_iter=10,                                  # Trainiere 10 zufällige Modelle (mit zufälligen Parametern)\n",
    "    scoring='neg_mean_squared_error',           # Wähle bestes Modell mit höchstem negativen MSE (bzw. tiefstem MSE).\n",
    "    random_state=0                              # Wir fixieren hier den random_state, so gibt es immer das gleiche Resultat. Wenn man diese Zeile entfernt nehmen wir andere Zufallswerte.\n",
    ")\n",
    "\n",
    "rs.fit(X, y)\n",
    "\n",
    "print(f\"{rs.best_params_=}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
