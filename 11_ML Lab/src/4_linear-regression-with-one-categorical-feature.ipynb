{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with a categorical feature\n",
    "\n",
    "In this notebook we create a `zipcode_2` feature from `zipcode` and use OneHotEncoding to add the `zipcode_2` feature to the model.\n",
    "\n",
    "First we show how this can be done manually (without using a `Pipeline`).\n",
    "Then we show how this can be done using a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:09.963339Z",
     "start_time": "2023-11-25T07:37:09.323119Z"
    },
    "papermill": {
     "duration": 0.952664,
     "end_time": "2020-11-12T13:41:11.650914",
     "exception": false,
     "start_time": "2020-11-12T13:41:10.698250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009145,
     "end_time": "2020-11-12T13:41:11.669935",
     "exception": false,
     "start_time": "2020-11-12T13:41:11.660790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.010124Z",
     "start_time": "2023-11-25T07:37:09.969756Z"
    },
    "papermill": {
     "duration": 0.092779,
     "end_time": "2020-11-12T13:41:11.789446",
     "exception": false,
     "start_time": "2020-11-12T13:41:11.696667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the train data\n",
    "train_data = pd.read_csv('../data/houses_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.023892Z",
     "start_time": "2023-11-25T07:37:10.023613Z"
    },
    "papermill": {
     "duration": 0.021139,
     "end_time": "2020-11-12T13:41:11.820019",
     "exception": false,
     "start_time": "2020-11-12T13:41:11.798880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into features and labels.\n",
    "X_data = train_data.drop(columns='price')\n",
    "y_data = train_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.045196Z",
     "start_time": "2023-11-25T07:37:10.024157Z"
    },
    "papermill": {
     "duration": 0.044926,
     "end_time": "2020-11-12T13:41:11.874527",
     "exception": false,
     "start_time": "2020-11-12T13:41:11.829601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split features and labels into train (X_train, y_train) and validation set (X_val, y_val).\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, stratify=X_data['object_type_name'], test_size=0.1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.049863Z",
     "start_time": "2023-11-25T07:37:10.045865Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Define and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Here we do the following steps:\n",
    "\n",
    "1. we create a new feature `zipcode_2` from `zipcode`\n",
    "2. we define the `OneHotEncoder` for `zipcode_2`.\n",
    "3. we \"train\" (`fit`) and apply (`transform`) the OneHotEncoder. We can think of `fit` in the `OneHotEncoder` as fixating the mapping, which `zipcode_2` value becomes the $i$th column in the output and `transform` as actually doing the `one-hot-encoding`.\n",
    "4. we combine the `living_area` feature with the features from the one-hot-encoded `zipcode_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.073366Z",
     "start_time": "2023-11-25T07:37:10.055449Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "X_train['zipcode_2'] = (X_train['zipcode'] // 100).astype(\"string\")\n",
    "\n",
    "# 2.\n",
    "zipcode_2 = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "\n",
    "# 3.\n",
    "X_train_zipcode_2 = zipcode_2.fit_transform(X_train[['zipcode_2']])\n",
    "X_train_zipcode_2 = pd.DataFrame(data=X_train_zipcode_2.toarray(), index=X_train.index, columns=zipcode_2.categories_[0][1:])\n",
    "\n",
    "# 4.\n",
    "X_train_ohe = pd.concat([\n",
    "    X_train[['living_area']],  # numerical features\n",
    "    X_train_zipcode_2,  # object_type_name OneHot features\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "`X_train_ohe` has now the `living_area` feature and features from the one-hot-encoded `zipcode_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.120862Z",
     "start_time": "2023-11-25T07:37:10.075805Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>living_area</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17153</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9619</th>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11971</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       living_area   11   12   13   14   15   16   17   18   19  ...   87  \\\n",
       "id                                                               ...        \n",
       "17153        145.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "9619         183.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "17291        113.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "11971        100.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "8171         200.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "        88   89   90   91   92   93   94   95   96  \n",
       "id                                                  \n",
       "17153  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9619   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17291  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11971  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "8171   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_ohe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we can train our `LinearRegression` model on this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.654900Z",
     "start_time": "2023-11-25T07:37:10.108778Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "_ = model.fit(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## What happened (Extra)\n",
    "\n",
    "What actually happened in the `fit` method of the `LinearRegression` model?\n",
    "We learned the parameters ($\\vec{\\beta}$) based on the training data.\n",
    "\n",
    "How many parameters did we learn?\n",
    "In the LinearRegression model, we learned one parameter for each feature, plus one parameter for the intercept.\n",
    "So given 84 features, we must have learned 85 parameters.\n",
    "\n",
    "Let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.655460Z",
     "start_time": "2023-11-25T07:37:10.287412Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  18281\n",
      "Number of features:  83\n",
      "Number of learned parameters:  84\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of train samples: \", f\"{X_train_ohe.shape[0]}\")\n",
    "print(f\"Number of features: \", f\"{X_train_ohe.shape[1]}\")\n",
    "# Note that model.coef_ is [ beta_1, beta_2, ..., beta_84 ] and model.intercept_ is beta_0 (that's why we + 1)\n",
    "print(f\"Number of learned parameters: \", f\"{model.coef_.shape[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We can also check the learned parameters (however they are not very interpretable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.655617Z",
     "start_time": "2023-11-25T07:37:10.299561Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  963159.2374660344\n",
      "Coef:  [   2240.79564974   73173.87790816  401642.21216112 -527289.17820154\n",
      " -426048.68807707 -506061.82402918 -518548.035423   -451090.52909644\n",
      " -325186.15778428 -303431.69696242 -288519.11200414 -892756.84750197\n",
      " -611985.40478249 -748732.03567946 -916001.6503796  -575283.84626315\n",
      " -784695.62093357 -915724.86984306 -698771.0574604  -933337.53546546\n",
      " -316275.70277934 -449551.58335277 -513487.53640805 -538596.52566167\n",
      " -598631.66392933 -660315.22930934 -430334.65925328 -422639.3682725\n",
      " -389379.25691229 -633851.75313312 -111779.34623067  -86714.18425032\n",
      " -494886.99320722 -406180.77962671 -447840.06044377 -605356.14260426\n",
      " -594994.99369375 -634574.53049514 -535367.83766766 -730879.72562519\n",
      " -454973.8649571  -581253.32807984 -506880.01074196 -564834.4613259\n",
      " -342649.56866792 -500053.85502461 -406911.86013547 -536327.70358486\n",
      " -181449.83841408 -628457.40904341 -372414.81302498   64601.02044068\n",
      " -159683.51154989 -365743.21210938 -140272.72553366 -752099.36929137\n",
      " -202175.21148206   12096.91301446 -315742.76811783 -596810.10717309\n",
      " -322488.78923965 -495708.6289967  -689072.34864588 -115164.35710307\n",
      " -959462.671932   -888977.06518269  292246.42386517 -140204.96532687\n",
      " -478519.64048631 -299118.86122665 -309414.61089794 -419862.45807289\n",
      " -188433.76652985  -61725.17068768 -145892.81602908 -167103.18861088\n",
      " -395089.84676767 -528379.64825538 -487027.63152212 -492928.45854487\n",
      " -504498.04680185 -403597.86920983 -615982.56676456]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Intercept: \", f\"{model.intercept_}\")\n",
    "print(f\"Coef: \", f\"{model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Predict and evaluate prices for the validation set\n",
    "\n",
    "The trained model will now be applied to the validation set.\n",
    "\n",
    "We have to **reuse** the `fitted` `OneHotEncoder` from the training set to transform the validation set.\n",
    "Reusing is critical, because the mapping has to be consistent for training set and validation set.\n",
    "\n",
    "We have to do the following steps:\n",
    "\n",
    "1. Prep validation data, note that the steps are the same as for the training data.\n",
    "2. Evaluate trained model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.655781Z",
     "start_time": "2023-11-25T07:37:10.308412Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.32520276759203\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "X_val['zipcode_2'] = (X_val['zipcode'] // 100).astype(\"string\")\n",
    "\n",
    "X_val_zipcode_2 = zipcode_2.transform(X_val[['zipcode_2']])\n",
    "X_val_zipcode_2 = pd.DataFrame(data=X_val_zipcode_2.toarray(), index=X_val.index, columns=zipcode_2.categories_[0][1:])\n",
    "\n",
    "X_val_ohe = pd.concat([\n",
    "    X_val[['living_area']],\n",
    "    X_val_zipcode_2\n",
    "], axis=1)\n",
    "\n",
    "# 2.\n",
    "y_val_pred = model.predict(X_val_ohe)\n",
    "print(mean_absolute_percentage_error(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This was tedious and error-prone.\n",
    "We have to be careful to apply the same steps to the validation set as we did to the training set.\n",
    "We can use a `Pipeline` to automate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Using a Pipeline\n",
    "\n",
    "**Here we do the same we did above but with a `Pipeline`.**\n",
    "\n",
    "A Pipeline describes a sequence of steps, which are applied to the data.\n",
    "\n",
    "Here our Pipeline consists of the following steps:\n",
    "\n",
    "1. `FunctionTransformer` to create the `zipcode_2` feature.\n",
    "2. `ColumnTransformer` to\n",
    "    a. one-hot-encode the `zipcode_2`\n",
    "    b. Keep the `living_area` feature\n",
    "    c. Drop all other feature except\n",
    "3. `LinearRegression` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.656612Z",
     "start_time": "2023-11-25T07:37:10.374630Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def create_zipcode_2(X: pd.DataFrame):\n",
    "    X['zipcode_2'] = (X['zipcode'] // 100).astype(\"string\")\n",
    "    return X\n",
    "\n",
    "# 1. Define Pipeline\n",
    "model = Pipeline([\n",
    "    # 1.\n",
    "    ('fe', FunctionTransformer(create_zipcode_2)),\n",
    "    # 2.\n",
    "    ('ohe', make_column_transformer(\n",
    "        (OneHotEncoder(handle_unknown='ignore'), ['zipcode_2']), # a. One-hot-encode zipcode_2\n",
    "        ('passthrough', ['living_area']), # b. Pass through living_area\n",
    "        remainder='drop' # c. Drop all other features\n",
    "    )),\n",
    "    # 3.\n",
    "    ('model', LinearRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now that we have defined the Pipeline, we can train it (1.) on the training data and evaluate it on the validation data (2.).\n",
    "\n",
    "Note that we do not have to apply the same steps to the validation data as we did to the training data. All steps are applied inside the `Pipeline` (automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T07:37:10.657302Z",
     "start_time": "2023-11-25T07:37:10.609466Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.32793068233405\n"
     ]
    }
   ],
   "source": [
    "# 1. Train Pipeline\n",
    "_ = model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict for prepared validation data\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(mean_absolute_percentage_error(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Given this example we hope you can see the advantages of using a `Pipeline`. It makes the code more readable and less error-prone. It also makes it easier to try out different models and different preprocessing steps. You can just add a new step to the Pipeline and you are good to go."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "duration": 6.853286,
   "end_time": "2020-11-12T13:41:13.194189",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-12T13:41:06.340903",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
